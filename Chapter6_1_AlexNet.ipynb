{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30696ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47edbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "class AlexNet(Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                        padding= 'valid', activation= 'relu',\n",
    "                        input_shape= input_shape,\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None)) \n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dense(1000, activation= 'relu'))\n",
    "        self.add(Dense(num_classes, activation= 'softmax'))\n",
    "\n",
    "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8061e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"alex_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 23, 23, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 11, 11, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 5, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 384)         1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              4198400   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,825,914\n",
      "Trainable params: 28,825,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet((100, 100, 3), num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab0999c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 385 images belonging to 2 classes.\n",
      "Found 98 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "image_height = 100\n",
    "image_width = 100\n",
    "\n",
    "train_dir = \"/Users/smk0728/Desktop/D_T_S/Image/chap6/data/catanddog/train\"\n",
    "valid_dir = \"/Users/smk0728/Desktop/D_T_S/Image/chap6/data/catanddog/validation\"\n",
    "\n",
    "train = ImageDataGenerator(\n",
    "                  rescale=1./255,\n",
    "                  rotation_range=10,\n",
    "                  width_shift_range=0.1,\n",
    "                  height_shift_range=0.1,\n",
    "                  shear_range=0.1,\n",
    "                  zoom_range=0.1)\n",
    "\n",
    "train_generator = train.flow_from_directory(train_dir,\n",
    "                                                    target_size=(image_height, image_width),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")\n",
    "\n",
    "valid = ImageDataGenerator(rescale=1.0/255.0)\n",
    "valid_generator = valid.flow_from_directory(valid_dir,\n",
    "                                                    target_size=(image_height, image_width),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    seed=7,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\"\n",
    "                                                    )\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35586250",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"../tensorboard/chap6/img/log6-2/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25eb7ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf2_book\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf2_book\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=train_num // BATCH_SIZE,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=valid_num // BATCH_SIZE,\n",
    "                    callbacks=[tensorboard_callback],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2814fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_book",
   "language": "python",
   "name": "tf2_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
